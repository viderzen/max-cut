{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import FixedEmbeddingComposite, EmbeddingComposite\n",
    "from dwave_networkx.algorithms.max_cut import maximum_cut\n",
    "from minorminer import find_embedding\n",
    "import dwave.inspector\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os, re\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict_from_file(fname):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : string\n",
    "        Name of a file that contains a dict\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    d : dict\n",
    "        Dictionary contained in the file\n",
    "    \"\"\"\n",
    "    with open(fname, mode='r') as f:\n",
    "        data = f.read()\n",
    "    d = ast.literal_eval(data)\n",
    "    return d\n",
    "\n",
    "def is_complete(graph):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : dict\n",
    "        Form: {edge: weight, ...}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    is_complete : bool\n",
    "        1 --> graph is complete, 0 --> graph is not complete\n",
    "    \"\"\"\n",
    "    num_nodes, num_edges = len(set( np.array(list( graph.keys() )).flatten() )), len(graph.keys())\n",
    "    return num_edges == num_nodes * (num_nodes - 1) / 2\n",
    "\n",
    "def normalize(edges):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    ----------\n",
    "    edges : dict\n",
    "        Form: {edge: weight, ...}\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    normalized_edges : dict\n",
    "        edges with normalized edge weights\n",
    "    \"\"\"\n",
    "    max_weight = np.max(np.absolute(list(edges.values())))\n",
    "    for edge in edges.keys():\n",
    "        edges[edge] /= max_weight\n",
    "    return edges\n",
    "\n",
    "def save_results(response, outfolder):\n",
    "    \"\"\" \n",
    "    Saves output of the annealing into 3 files ('embedding.txt', 'solution.txt', 'timing.txt') in outfolder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    response : D-Wave SampleSet\n",
    "        Outpu of the annealing\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    def mkdir(dirname):\n",
    "        try:\n",
    "            os.mkdir(dirname)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "    mkdir(outfolder)\n",
    "    \n",
    "    with open(os.path.join(outfolder, 'embedding.txt'), mode='w') as outfile:\n",
    "        outfile.write(json.dumps(response.info['embedding_context']['embedding']))\n",
    "    \n",
    "    with open(os.path.join(outfolder, 'solution.txt'), mode='w') as outfile:\n",
    "        d = {'solution': response.first.sample, 'energy': response.first.energy, 'chain_break_fraction': response.first.chain_break_fraction.round(5)}\n",
    "        outfile.write(str(d))\n",
    "    \n",
    "    with open(os.path.join(outfolder, 'timing.txt'), mode='w') as outfile:\n",
    "        outfile.write(json.dumps(response.info['timing']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to a sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 100\n",
    "annealing_time = 30\n",
    "\n",
    "for i, fname in enumerate(os.listdir(os.path.join(os.getcwd(), 'graphs_python_dictionary'))):\n",
    "\n",
    "    if i == 1: break\n",
    "    fname = 'be150.8.1_py.txt'\n",
    "\n",
    "    print(str(i) + ': ' + fname, end='\\t')\n",
    "\n",
    "    # read problem from a file\n",
    "    J_dict = read_dict_from_file(os.path.join('graphs_python_dictionary', fname))\n",
    "    max_chain_strength = np.max(np.absolute(list(J_dict.values())))\n",
    "\n",
    "    # set up field dict to 0 (DWave sampler wants it)\n",
    "    h_dict = {}\n",
    "    for node1, node2 in J_dict.keys():\n",
    "        h_dict[node2] = 0.0\n",
    "        h_dict[node1] = 0.0\n",
    "\n",
    "    # create a problem graph to find embedding\n",
    "    G = nx.Graph(J_dict.keys())\n",
    "\n",
    "    # connect to solver\n",
    "    sampler = DWaveSampler(profile='viderzen_protonmail')\n",
    "    max_slope = 1 / sampler.properties['annealing_time_range'][0]\n",
    "\n",
    "    # find embedding of a problem on DWave QPU\n",
    "    embedding = find_embedding(G, sampler.properties['couplers'], verbose=3)\n",
    "    \n",
    "    # sample problem solutions\n",
    "    sampler = FixedEmbeddingComposite(sampler, embedding)\n",
    "    response1 = sampler.sample_ising(h_dict, J_dict, num_reads=num_reads, annealing_time=annealing_time, chain_strength=2.5*max_chain_strength)\n",
    "\n",
    "    # use best solution (min energy) and check for better solutions in its vicinity with reverse annealing\n",
    "    s = 0.45\n",
    "    init_state = response1.first.sample\n",
    "    anneal_schedule = [[0, 1], [(1-s)/max_slope, s], [(1-s)/max_slope + annealing_time, s], [2*(1-s)/max_slope + annealing_time, 1]]\n",
    "    response2 = sampler.sample_ising(h_dict, J_dict, num_reads=num_reads, chain_strength=2.5*max_chain_strength, anneal_schedule=anneal_schedule, \n",
    "                                    initial_state=init_state, reinitialize_state=True)\n",
    "\n",
    "    # save results and info about results to files\n",
    "    save_results(response2, os.path.join('results', fname[:-7]))\n",
    "\n",
    "    print('Done.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fe50e45861d646d87f8db73a1c019971d842817891d80b145d56744a8c41849"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ocean': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
